{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mosta\\AppData\\Local\\Temp\\tmp8vftxhio\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mosta\\AppData\\Local\\Temp\\tmp8vftxhio\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model loaded and allocated tensors.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('bestModel.h5')\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "#tflite_model = converter.convert()\n",
    "# Save the converted model to a file\n",
    "#with open('model.tflite', 'wb') as f:\n",
    "#    f.write(tflite_model)\n",
    "\n",
    "# Load the TFLite model\n",
    "#interpreter = tf.lite.Interpreter(model_path='bestModel.tflite')\n",
    "#interpreter.allocate_tensors()\n",
    "\n",
    "# Print model details\n",
    "#print(\"TFLite model loaded and allocated tensors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#cap = cv2.VideoCapture(0)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#cap = cv2.VideoCapture('Speed.mp4')\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Set resolution and frame rate\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS, \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     24\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH, \u001b[38;5;241m150\u001b[39m)\n\u001b[0;32m     25\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_HEIGHT, \u001b[38;5;241m150\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "\n",
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('haarcascade_righteye_2splits.xml')\n",
    "\n",
    "lbl=['Close','Open']\n",
    "\n",
    "model = load_model('bestModel.h5')\n",
    "path = os.getcwd()\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('Speed.mp4')\n",
    "\n",
    "# Set resolution and frame rate\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 150)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 150)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    height,width = frame.shape[:2] \n",
    "\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(150,150))\n",
    "    left_eye = leye.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(50,50))\n",
    "    right_eye =  reye.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(50,50))\n",
    "\n",
    "\n",
    "    cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "\n",
    "    for (x,y,w,h) in right_eye:\n",
    "        r_eye=frame[y:y+h,x:x+w]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        count=count+1\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye,(64,64))\n",
    "        r_eye=  r_eye.reshape((-1, 64, 64, 1))\n",
    "        r_eye = r_eye/255.0\n",
    "\n",
    "        rpred = model.predict(r_eye)\n",
    "        print(rpred)\n",
    "        if(rpred[0]>0.5):\n",
    "            lbl='Open' \n",
    "        if(rpred[0]<=0.5):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    for (x,y,w,h) in left_eye:\n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        count=count+1\n",
    "        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "        l_eye = cv2.resize(l_eye,(64,64))\n",
    "        l_eye=l_eye.reshape((-1, 64, 64, 1))\n",
    "        l_eye = l_eye/255.0\n",
    "        \n",
    "        lpred = model.predict(l_eye)\n",
    "        print(lpred)\n",
    "        if(lpred[0]>0.5):\n",
    "            lbl='Open'   \n",
    "        if(lpred[0]<=0.5):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "    \n",
    "\n",
    "    if(rpred[0]<=0.5 and lpred[0]<=0.5):\n",
    "        score=score+1\n",
    "        cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    # if(rpred[0]==1 or lpred[0]==1):\n",
    "    else:\n",
    "        score=score-1\n",
    "        cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "        \n",
    "    if(score<0):\n",
    "        score=0   \n",
    "    cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    if(score>12):\n",
    "        #person is feeling sleepy so we beep the alarm\n",
    "        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "        #try:\n",
    "        #    sound.play()\n",
    "            \n",
    "        #except:  # isplaying = False\n",
    "        #    pass\n",
    "        if(thicc<16):\n",
    "            thicc= thicc+2\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "        cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc) \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
